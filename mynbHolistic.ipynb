{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mynbHolistic.ipynb","provenance":[],"collapsed_sections":["cE07fhTfzfP_","tKXbnaZezMHx","omgf83cruxRd","m8A-Ff6lztCH"],"machine_shape":"hm","authorship_tag":"ABX9TyP6p5A8UnMlmDVhyOB0WY73"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Mount Drive"],"metadata":{"id":"J9gDttJ1zZZK"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNmS5JQZ_mx-","executionInfo":{"status":"ok","timestamp":1650658068397,"user_tz":240,"elapsed":1437,"user":{"displayName":"Seth Howells","userId":"08049334453680049674"}},"outputId":"11e987e0-b392-4967-cce1-791ec0b6a422"},"outputs":[{"output_type":"stream","name":"stdout","text":["/\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","ln: failed to create symbolic link '/mydrive/My Drive': File exists\n","'2022-04-06 21-23.pdf'\t\t    mediapipe-main\n"," ColabNB\t\t\t   'My Drive'\n","'Colab Notebooks'\t\t    Other\n","'Copy of Tumor_CNN_denoise.ipynb'   Tumor2\n"," Data-Viz\t\t\t   'Untitled document.gdoc'\n"," DistCompSys\t\t\t    videoplayback.mp4\n"," GSVPanoDepth.js-master\t\t    videos\n"," Howells_bslevels.gsheet\t    yolov4\n"," images\n","/content/gdrive/My Drive/mediapipe-main\n"]}],"source":["#mount drive\n","%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","\n","# list the contents of /mydrive\n","!ls /mydrive\n","\n","#Navigate to /mydrive/mediapipe-main\n","%cd /mydrive/mediapipe-main"]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"cE07fhTfzfP_"}},{"cell_type":"code","source":["!pip install mediapipe\n","!pip install kaleido\n","!pip install PyQt5\n","!pip install IPython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3QlE790SzXWR","executionInfo":{"status":"ok","timestamp":1650658085856,"user_tz":240,"elapsed":11875,"user":{"displayName":"Seth Howells","userId":"08049334453680049674"}},"outputId":"0627b908-e832-4524-921c-4a9e96f77fad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.9.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.0.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n","Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: PyQt5 in /usr/local/lib/python3.7/dist-packages (5.15.6)\n","Requirement already satisfied: PyQt5-Qt5>=5.15.2 in /usr/local/lib/python3.7/dist-packages (from PyQt5) (5.15.2)\n","Requirement already satisfied: PyQt5-sip<13,>=12.8 in /usr/local/lib/python3.7/dist-packages (from PyQt5) (12.10.1)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython) (0.8.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython) (5.1.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython) (0.7.0)\n"]}]},{"cell_type":"code","source":["from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from google.colab import files\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import PIL\n","import io\n","import glob\n","import os\n","import datetime\n","import imutils\n","import time\n","from time import sleep\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import mediapipe as mp\n","import nb_helpers"],"metadata":{"id":"a9vbvbBK_1mv","executionInfo":{"status":"ok","timestamp":1650658085857,"user_tz":240,"elapsed":15,"user":{"displayName":"Seth Howells","userId":"08049334453680049674"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Jave Helper functions for real-time webcam use with Colab"],"metadata":{"id":"tKXbnaZezMHx"}},{"cell_type":"code","source":["#\n","# based on: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n","#\n","\n","def init_camera():\n","  \"\"\"Create objects and functions in HTML/JavaScript to access local web camera\"\"\"\n","\n","  js = Javascript('''\n","\n","    // global variables to use in both functions\n","    var div = null;\n","    var video = null;   // <video> to display stream from local webcam\n","    var stream = null;  // stream from local webcam\n","    var canvas = null;  // <canvas> for single frame from <video> and convert frame to JPG\n","    var img = null;     // <img> to display JPG after processing with `cv2`\n","\n","    async function initCamera() {\n","      // place for video (and eventually buttons)\n","      div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      // <video> to display video\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      div.appendChild(video);\n","\n","      // get webcam stream and assing to <video>\n","      stream = await navigator.mediaDevices.getUserMedia({video: true});\n","      video.srcObject = stream;\n","\n","      // start playing stream from webcam in <video>\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // <canvas> for frame from <video>\n","      canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      //div.appendChild(input_canvas); // there is no need to display to get image (but you can display it for test)\n","\n","      // <img> for image after processing with `cv2`\n","      img = document.createElement('img');\n","      img.width = video.videoWidth;\n","      img.height = video.videoHeight;\n","      div.appendChild(img);\n","    }\n","\n","    async function takeImage(quality) {\n","      // draw frame from <video> on <canvas>\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","\n","      // stop webcam stream\n","      //stream.getVideoTracks()[0].stop();\n","\n","      // get data from <canvas> as JPG image decoded base64 and with header \"data:image/jpg;base64,\"\n","      return canvas.toDataURL('image/jpeg', quality);\n","      //return canvas.toDataURL('image/png', quality);\n","    }\n","\n","    async function showImage(image) {\n","      // it needs string \"data:image/jpg;base64,JPG-DATA-ENCODED-BASE64\"\n","      // it will replace previous image in `<img src=\"\">`\n","      img.src = image;\n","      // TODO: create <img> if doesn't exists, \n","      // TODO: use `id` to use different `<img>` for different image - like `name` in `cv2.imshow(name, image)`\n","    }\n","\n","  ''')\n","\n","  display(js)\n","  eval_js('initCamera()')\n","\n","def take_frame(quality=0.5):\n","  \"\"\"Get frame from web camera\"\"\"\n","\n","  data = eval_js('takeImage({})'.format(quality))  # run JavaScript code to get image (JPG as string base64) from <canvas>\n","\n","  header, data = data.split(',')  # split header (\"data:image/jpg;base64,\") and base64 data (JPG)\n","  data = b64decode(data)  # decode base64\n","  data = np.frombuffer(data, dtype=np.uint8)  # create numpy array with JPG data\n","\n","  img = cv2.imdecode(data, cv2.IMREAD_UNCHANGED)  # uncompress JPG data to array of pixels\n","\n","  return img\n","\n","def show_frame(img, quality=0.5):\n","  \"\"\"Put frame as <img src=\"data:image/jpg;base64,....\"> \"\"\"\n","\n","  ret, data = cv2.imencode('.jpg', img)  # compress array of pixels to JPG data\n","\n","  data = b64encode(data)  # encode base64\n","  data = data.decode()  # convert bytes to string\n","  data = 'data:image/jpg;base64,' + data  # join header (\"data:image/jpg;base64,\") and base64 data (JPG)\n","\n","  eval_js('showImage(\"{}\")'.format(data))  # run JavaScript code to put image (JPG as string base64) in <img>\n","                                           # argument in `showImage` needs `\" \"` "],"metadata":{"id":"X7HEfTLh_4ZP","executionInfo":{"status":"ok","timestamp":1650658086125,"user_tz":240,"elapsed":6,"user":{"displayName":"Seth Howells","userId":"08049334453680049674"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import plotly.graph_objects as go\n","import plotly.express as px\n","\n","_PRESENCE_THRESHOLD = 0.5\n","_VISIBILITY_THRESHOLD = 0.5\n","\n","def plot_landmarks(counter,\n","    landmark_list,\n","    connections=None,\n","    ):\n","    \n","    if not landmark_list:\n","        return\n","    plotted_landmarks = {}\n","    for idx, landmark in enumerate(landmark_list.landmark):\n","        if (\n","            landmark.HasField(\"visibility\")\n","            and landmark.visibility < _VISIBILITY_THRESHOLD\n","        ) or (\n","            landmark.HasField(\"presence\") and landmark.presence < _PRESENCE_THRESHOLD\n","        ):\n","            continue\n","        plotted_landmarks[idx] = (-landmark.z, landmark.x, -landmark.y)\n","    if connections:\n","        out_cn = []\n","        num_landmarks = len(landmark_list.landmark)\n","        # Draws the connections if the start and end landmarks are both visible.\n","        for connection in connections:\n","            start_idx = connection[0]\n","            end_idx = connection[1]\n","            if not (0 <= start_idx < num_landmarks and 0 <= end_idx < num_landmarks):\n","                raise ValueError(\n","                    f\"Landmark index is out of range. Invalid connection \"\n","                    f\"from landmark #{start_idx} to landmark #{end_idx}.\"\n","                )\n","            if start_idx in plotted_landmarks and end_idx in plotted_landmarks:\n","                landmark_pair = [\n","                    plotted_landmarks[start_idx],\n","                    plotted_landmarks[end_idx],\n","                ]\n","                out_cn.append(\n","                    dict(\n","                        xs=[landmark_pair[0][0], landmark_pair[1][0]],\n","                        ys=[landmark_pair[0][1], landmark_pair[1][1]],\n","                        zs=[landmark_pair[0][2], landmark_pair[1][2]],\n","                    )\n","                )\n","        cn2 = {\"xs\": [], \"ys\": [], \"zs\": []}\n","        for pair in out_cn:\n","            for k in pair.keys():\n","                cn2[k].append(pair[k][0])\n","                cn2[k].append(pair[k][1])\n","                cn2[k].append(None)\n","\n","    df = pd.DataFrame(plotted_landmarks).T.rename(columns={0: \"z\", 1: \"x\", 2: \"y\"})\n","    df[\"lm\"] = df.index.map(lambda s: mp_pose.PoseLandmark(s).name).values\n","    fig = (\n","        px.scatter_3d(df, x=\"z\", y=\"x\", z=\"y\", hover_name=\"lm\")\n","        .update_traces(marker={\"color\": \"red\"})\n","        .update_layout(\n","            margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0},\n","            scene={\"camera\": {\"eye\": {\"x\": 2.1, \"y\": 0, \"z\": 0}}},\n","        )\n","    )\n","    fig.add_traces(\n","        [\n","            go.Scatter3d(\n","                x=cn2[\"xs\"],\n","                y=cn2[\"ys\"],\n","                z=cn2[\"zs\"],\n","                mode=\"lines\",\n","                line={\"color\": \"black\", \"width\": 5},\n","                name=\"connections\",\n","            )\n","        ]\n","    )\n","\n","    return fig.show()"],"metadata":{"id":"StSlnx_MA11-","executionInfo":{"status":"ok","timestamp":1650658107299,"user_tz":240,"elapsed":1087,"user":{"displayName":"Seth Howells","userId":"08049334453680049674"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Holistic Body Pose w/ Real-Time webcam"],"metadata":{"id":"okPQ0oUEzkg5"}},{"cell_type":"markdown","source":["## With Plots"],"metadata":{"id":"omgf83cruxRd"}},{"cell_type":"code","source":["mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_holistic = mp.solutions.holistic\n","mp_pose = mp.solutions.pose\n","mp_face_mesh = mp.solutions.face_mesh\n","drawing_spec = mp_drawing.DrawingSpec(color=(0,255,0),thickness=1, circle_radius=1)\n","mp.solutions.pose.PoseLandmark\n","holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","\n","# start streaming video from webcam\n","init_camera()\n","label_html = 'Capturing...' # label for video\n","bbox = ''                   # initialze bounding box to empty\n","\n","# Define the codec and create VideoWriter object\n","#fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","#out = cv2.VideoWriter('faceDetect_direction4.mp4',fourcc, 3.0, (640,480))\n","\n","\n","while True:\n","  try:\n","    frame = take_frame()\n","    \n","    start = time.time()\n","    image = cv2.cvtColor(cv2.flip(frame, 2), cv2.COLOR_BGR2RGB)\n","    image.flags.writeable = False\n","    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","\n","    if results.pose_landmarks:\n","      # Draw landmark annotation on the image.\n","      image.flags.writeable = True\n","      image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","      img_h, img_w, img_c = image.shape\n","      \n","      end = time.time()\n","      totalTime = end - start\n","      fps = 1 / totalTime\n","      #print(\"FPS: \", fps)\n","\n","      cv2.putText(image, f'FPS: {int(fps)}', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)  \n","\n","      # Draw pose, left and right hands, and face landmarks on the image.\n","      mp_drawing.draw_landmarks(\n","          image = image,\n","          landmark_list = results.face_landmarks,\n","          connections = mp_holistic.FACEMESH_CONTOURS,\n","          landmark_drawing_spec = None,\n","          connection_drawing_spec = mp_drawing_styles\n","          .get_default_face_mesh_tesselation_style())\n","      mp_drawing.draw_landmarks(\n","          image = image,\n","          landmark_list = results.pose_landmarks,\n","          connections = mp_holistic.POSE_CONNECTIONS,\n","          landmark_drawing_spec = mp_drawing_styles.\n","          get_default_pose_landmarks_style())\n","\n","    # Plot pose world landmarks.\n","    #plot_landmarks(image, results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n","\n","    #out.write(image)    \n","    show_frame(image)\n","  except Exception as err:\n","    print('Exception:', err)\n","\n","#out.release()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hSScAbzz8nnU","executionInfo":{"status":"error","timestamp":1650658310849,"user_tz":240,"elapsed":19709,"user":{"displayName":"Seth Howells","userId":"08049334453680049674"}},"outputId":"441cc1ff-5c65-4048-86d8-6a5d6e0969f3"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","\n","    // global variables to use in both functions\n","    var div = null;\n","    var video = null;   // <video> to display stream from local webcam\n","    var stream = null;  // stream from local webcam\n","    var canvas = null;  // <canvas> for single frame from <video> and convert frame to JPG\n","    var img = null;     // <img> to display JPG after processing with `cv2`\n","\n","    async function initCamera() {\n","      // place for video (and eventually buttons)\n","      div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      // <video> to display video\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      div.appendChild(video);\n","\n","      // get webcam stream and assing to <video>\n","      stream = await navigator.mediaDevices.getUserMedia({video: true});\n","      video.srcObject = stream;\n","\n","      // start playing stream from webcam in <video>\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // <canvas> for frame from <video>\n","      canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      //div.appendChild(input_canvas); // there is no need to display to get image (but you can display it for test)\n","\n","      // <img> for image after processing with `cv2`\n","      img = document.createElement('img');\n","      img.width = video.videoWidth;\n","      img.height = video.videoHeight;\n","      div.appendChild(img);\n","    }\n","\n","    async function takeImage(quality) {\n","      // draw frame from <video> on <canvas>\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","\n","      // stop webcam stream\n","      //stream.getVideoTracks()[0].stop();\n","\n","      // get data from <canvas> as JPG image decoded base64 and with header \"data:image/jpg;base64,\"\n","      return canvas.toDataURL('image/jpeg', quality);\n","      //return canvas.toDataURL('image/png', quality);\n","    }\n","\n","    async function showImage(image) {\n","      // it needs string \"data:image/jpg;base64,JPG-DATA-ENCODED-BASE64\"\n","      // it will replace previous image in `<img src=\"\">`\n","      img.src = image;\n","      // TODO: create <img> if doesn't exists, \n","      // TODO: use `id` to use different `<img>` for different image - like `name` in `cv2.imshow(name, image)`\n","    }\n","\n","  "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f783e7caa7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-c446c530bdb9>\u001b[0m in \u001b[0;36mtake_frame\u001b[0;34m(quality)\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;34m\"\"\"Get frame from web camera\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takeImage({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run JavaScript code to get image (JPG as string base64) from <canvas>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# split header (\"data:image/jpg;base64,\") and base64 data (JPG)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["        # Draw segmentation on the image.\n","        # To improve segmentation around boundaries, consider applying a joint\n","        # bilateral filter to \"results.segmentation_mask\" with \"image\".\n","        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n","        bg_image = np.zeros(image.shape, dtype=np.uint8)\n","        bg_image[:] = BG_COLOR\n","        image = np.where(condition, image, bg_image)"],"metadata":{"id":"SsUTBTBroyal"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["            # Draw pose, left and right hands, and face landmarks on the image.\n","            mp_drawing.draw_landmarks(\n","                image = image,\n","                landmark_list = results.face_landmarks,\n","                connections = mp_holistic.FACEMESH_TESSELATION,\n","                landmark_drawing_spec = None,\n","                connection_drawing_spec = mp_drawing_styles\n","                .get_default_face_mesh_tesselation_style())\n","            mp_drawing.draw_landmarks(\n","                image = image,\n","                landmark_list = results.pose_landmarks,\n","                connections = mp_holistic.POSE_CONNECTIONS,\n","                landmark_drawing_spec = mp_drawing_styles.\n","                get_default_pose_landmarks_style())\n","      "],"metadata":{"id":"YntdMWB9oyXm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"6krgraMaoyST"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Graphing Pose"],"metadata":{"id":"m8A-Ff6lztCH"}},{"cell_type":"code","source":[""],"metadata":{"id":"gin28ZsBmKA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"SQxDs8cvmJ84"},"execution_count":null,"outputs":[]}]}